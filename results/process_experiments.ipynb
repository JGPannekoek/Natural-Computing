{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8d72cc5-027d-433e-8db3-93266db564fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial import distance_matrix\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa2b3e1-8071-4f8a-9390-43d30f56bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ResultSet:\n",
    "    \"\"\"\n",
    "    Helper class to keep all results from a single experiment together\n",
    "    \"\"\"\n",
    "    path: str\n",
    "    all_trails: np.array\n",
    "    seed: np.array\n",
    "    nuclei: np.array\n",
    "    stations: np.array\n",
    "    map_with_stations: np.array\n",
    "    start_pos: np.array\n",
    "    all_points: np.array = field(init=False)\n",
    "    station_indices: range = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        points = self.nuclei.reshape(-1, 2)\n",
    "        points = points[~np.all(points == 0, axis=1)]  # Remove zero points\n",
    "        self.all_points = np.vstack([points, self.stations])\n",
    "        \n",
    "        self.station_indices = range(self.all_points.shape[0] - len(self.stations), self.all_points.shape[0])\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Experiment with start pos {self.start_pos}, seed {self.seed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "001822da-15f7-461e-8802-8c61506daa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nuclei_graph(results: ResultSet) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Creates a graph from all slime nuclei, where every node is connected to\n",
    "    its 10 closest neighbours\n",
    "    \"\"\"\n",
    "    \n",
    "    # 2. Build KDTree for fast neighbor search\n",
    "    tree = cKDTree(results.all_points)\n",
    "    \n",
    "    # 3. For each point, find its pm=10 nearest neighbors (excluding itself)\n",
    "    pm = 10\n",
    "    dists, idxs = tree.query(results.all_points, k=pm+1)  # +1 because first neighbor is itself\n",
    "    \n",
    "    # 4. Build the proximity graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # idxs: shape (N, pm+1), where idxs[i, 0] == i (self), idxs[i, 1:] are neighbors\n",
    "    src = np.repeat(np.arange(idxs.shape[0]), idxs.shape[1] - 1)\n",
    "    dst = idxs[:, 1:].reshape(-1) \n",
    "    edges = np.stack([src, dst], axis=1) # shape (N*(pm-1), 2)\n",
    "    \n",
    "    # Compute edge weights (Euclidean distances)\n",
    "    diffs = results.all_points[edges[:, 0]] - results.all_points[edges[:, 1]]\n",
    "    weights = np.linalg.norm(diffs, axis=1)\n",
    "    \n",
    "    # Add all edges at once to the graph\n",
    "    G.add_weighted_edges_from([(int(i), int(j), float(w)) for (i, j), w in zip(edges, weights)])\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f590b468-c6f2-4ca3-bb2f-19b42b88e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bresenham_line(x0, y0, x1, y1):\n",
    "    \"\"\"Yield integer coordinates on the line from (x0, y0) to (x1, y1) using Bresenham's algorithm.\"\"\"\n",
    "    x0, y0, x1, y1 = int(round(x0)), int(round(y0)), int(round(x1)), int(round(y1))\n",
    "    dx = abs(x1 - x0)\n",
    "    dy = abs(y1 - y0)\n",
    "    x, y = x0, y0\n",
    "    sx = 1 if x0 < x1 else -1\n",
    "    sy = 1 if y0 < y1 else -1\n",
    "    if dx > dy:\n",
    "        err = dx / 2.0\n",
    "        while x != x1:\n",
    "            yield x, y\n",
    "            err -= dy\n",
    "            if err < 0:\n",
    "                y += sy\n",
    "                err += dx\n",
    "            x += sx\n",
    "        yield x, y\n",
    "    else:\n",
    "        err = dy / 2.0\n",
    "        while y != y1:\n",
    "            yield x, y\n",
    "            err -= dx\n",
    "            if err < 0:\n",
    "                x += sx\n",
    "                err += dy\n",
    "            y += sy\n",
    "        yield x, y\n",
    "\n",
    "def prune_edges_by_map(G, result_set, max_water_crossings=2):\n",
    "    \"\"\"\n",
    "    Prunes illegal edges by checking the number of invalid pixels on a line \n",
    "    \"\"\"\n",
    "    pruned_graph = nx.Graph()\n",
    "    for i, j in G.edges():\n",
    "        x0, y0 = result_set.all_points[i]\n",
    "        x1, y1 = result_set.all_points[j]\n",
    "        # Sample the line between the two points\n",
    "        line_pixels = list(bresenham_line(x0, y0, x1, y1))\n",
    "        # Count how many pixels cross water (0)\n",
    "        water_crossings = sum(\n",
    "            result_set.map_with_stations[int(x), int(y)] == 0\n",
    "            for x, y in line_pixels\n",
    "            if 0 <= int(x) < result_set.map_with_stations.shape[0] and 0 <= int(y) < result_set.map_with_stations.shape[1]\n",
    "        )\n",
    "        if water_crossings <= max_water_crossings:\n",
    "            pruned_graph.add_edge(i, j, weight=G[i][j]['weight'])\n",
    "    return pruned_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb174ddf-6177-4cbd-8c95-408595e9de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_shortest_paths(G, stations):\n",
    "    paths = defaultdict(list)\n",
    "    distances = defaultdict(dict)\n",
    "        \n",
    "    for i in range(len(stations)):\n",
    "        source = stations[i]\n",
    "        for j in range(len(stations)):\n",
    "            if i == j: continue\n",
    "            try:\n",
    "                target = stations[j]\n",
    "                length, path = nx.single_source_dijkstra(G, source=str(source), target=str(target), weight='weight')\n",
    "                paths[source].append((length, path, target))\n",
    "                distances[source][target] = length\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "\n",
    "    return paths, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa85a9b1-5096-4ae0-848a-8b517bdaa13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_refined_station_network(G, results, proximities):\n",
    "    \"\"\"\n",
    "    Build a refined network connecting each station to its p nearest station neighbors,\n",
    "    using only mesh edges from the original graph G.\n",
    "    \"\"\"\n",
    "    graphs = []\n",
    "    for p in proximities:\n",
    "        graphs.append(nx.Graph())\n",
    "\n",
    "    all_paths, distances = find_shortest_paths(G, results.station_indices)\n",
    "\n",
    "    for source, paths in all_paths.items():\n",
    "        paths = sorted(paths, key=lambda p: p[0])\n",
    "        \n",
    "        for p in range(len(proximities)):\n",
    "            p_graph = graphs[p]\n",
    "            proximity = proximities[p]\n",
    "            for length, path, target in paths[:proximity]:\n",
    "                p_graph.add_weighted_edges_from((str(path[k]), str(path[k+1]), G[path[k]][path[k+1]]['weight']) for k in range(len(path)-1))\n",
    "\n",
    "    for p in range(len(proximities)):\n",
    "        nx.write_weighted_edgelist(graphs[p], results.path + f'.p{proximities[p]}.weighted.edgelist')\n",
    "    \n",
    "    with open(results.path + '.distances.json', 'w') as f: \n",
    "        json.dump(distances, f)\n",
    "                \n",
    "    return graphs, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93ec9761-c057-485f-a00c-5d5f59fc6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_network_cost(G):\n",
    "    \"\"\"\n",
    "    Calculates the cost of the total network\n",
    "    \"\"\"\n",
    "    return G.size('weight')\n",
    "\n",
    "def calculate_mean_travel_time(distances):\n",
    "    \"\"\"\n",
    "    Calculates the mean travel time on the network\n",
    "    \"\"\"\n",
    "    means = []\n",
    "    for source, targets in distances.items():\n",
    "        source_mean = sum(t for t in targets.values()) / len(targets)\n",
    "        means.append(source_mean)\n",
    "\n",
    "    return np.mean(means)\n",
    "    \n",
    "def calculate_network_vulnerability(G, ref_travel_time, results):\n",
    "    \"\"\"\n",
    "    Calculates the mean vulnerability on the network.\n",
    "    If the graph becomes disconnected after an edge is removed,\n",
    "    the vulnerability is then the weight of that edge.\n",
    "    \"\"\"\n",
    "    vulnerabilities = []\n",
    "    full_cost = calculate_network_cost(G)\n",
    "\n",
    "    for e in tqdm(G.edges()):\n",
    "        # print(f'Processing edge {e}')\n",
    "        # Create a copy of the graph to avoid modifying the original\n",
    "        G_copy = G.copy()\n",
    "        G_copy.remove_edge(*e)\n",
    "        \n",
    "        distances = dict(nx.all_pairs_shortest_path_length(G_copy))\n",
    "        mean_time = calculate_mean_travel_time(distances)\n",
    "        vuln = np.abs(ref_travel_time - mean_time)\n",
    "        \n",
    "        if not nx.is_connected(G_copy):\n",
    "            vuln += full_cost\n",
    "            \n",
    "        vulnerabilities.append(vuln)\n",
    "    return np.mean(vulnerabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ddb7f288-e429-4838-abe2-76de336b4eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(path: str) -> ResultSet:\n",
    "    \"\"\"\n",
    "    Process a single result file\n",
    "    \"\"\"\n",
    "    with np.load(path) as data:\n",
    "        return ResultSet(path=path,\n",
    "                         all_trails = data['all_trails'],\n",
    "                         seed = data['seed'],\n",
    "                         nuclei = data['nuclei'],\n",
    "                         stations = data['stations'],\n",
    "                         map_with_stations = data['map_with_stations'],\n",
    "                         start_pos = data['start_pos'])\n",
    "\n",
    "def process_folder(dir_path: str, proximities):\n",
    "    \"\"\"\n",
    "    Process a folder containing experiment result files.\n",
    "    \"\"\"\n",
    "    full_path = dir_path + \"/*.npz\"\n",
    "    files = glob(full_path)\n",
    "    \n",
    "    results = []\n",
    "    for i in trange(len(files)):\n",
    "        path = files[i]\n",
    "        result_set = process_file(path)\n",
    "        full_graph = create_nuclei_graph(result_set)\n",
    "        pruned_graph = prune_edges_by_map(full_graph, result_set)\n",
    "\n",
    "        if os.path.exists(path + '.distances.json'):\n",
    "            with open(path + '.distances.json', 'r') as f: \n",
    "                distances = json.load(f)\n",
    "            graphs = []\n",
    "            for p in proximities:\n",
    "                graphs.append(nx.read_weighted_edgelist(path + f'.p{p}.weighted.edgelist'))\n",
    "        else:\n",
    "            graphs, distances = build_refined_station_network(pruned_graph, result_set, proximities)\n",
    "            \n",
    "        for p in range(len(proximities)):\n",
    "            graph = graphs[p]\n",
    "            proximity = proximities[p]\n",
    "            total_cost = calculate_network_cost(graph)\n",
    "            mean_travel_time = calculate_mean_travel_time(distances)\n",
    "            network_vulnerability = calculate_network_vulnerability(graph, mean_travel_time, result_set)\n",
    "            is_connected = nx.is_connected(graph)\n",
    "    \n",
    "            results.append((proximity, result_set.start_pos[0], result_set.start_pos[1], result_set.seed, \n",
    "                            total_cost, mean_travel_time, network_vulnerability, is_connected))\n",
    "    \n",
    "    df = pd.DataFrame(results, columns=[\"proximity\", \"start_pos_x\", \"start_pos_y\", \"seed\", \n",
    "                                        \"total_cost\", \"mean_travel_time\", \"vulnerability\", \"is_connected\"])\n",
    "    df_path = dir_path + f\"/results.csv\"\n",
    "    df.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "448c0c8b-2825-4239-b80c-bf61959d7843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0d1621afcc47e3b5c092b80d8c561a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137c6cf70be54c49af3b522a8019a3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1753 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m proximities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Process experiments\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mprocess_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../experiment_outputs_different_starts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproximities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m process_folder(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../experiment_outputs_same_starts\u001b[39m\u001b[38;5;124m\"\u001b[39m, proximities)\n",
      "Cell \u001b[0;32mIn[69], line 42\u001b[0m, in \u001b[0;36mprocess_folder\u001b[0;34m(dir_path, proximities)\u001b[0m\n\u001b[1;32m     40\u001b[0m total_cost \u001b[38;5;241m=\u001b[39m calculate_network_cost(graph)\n\u001b[1;32m     41\u001b[0m mean_travel_time \u001b[38;5;241m=\u001b[39m calculate_mean_travel_time(distances)\n\u001b[0;32m---> 42\u001b[0m network_vulnerability \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_network_vulnerability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_travel_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m is_connected \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mis_connected(graph)\n\u001b[1;32m     45\u001b[0m results\u001b[38;5;241m.\u001b[39mappend((proximity, result_set\u001b[38;5;241m.\u001b[39mstart_pos[\u001b[38;5;241m0\u001b[39m], result_set\u001b[38;5;241m.\u001b[39mstart_pos[\u001b[38;5;241m1\u001b[39m], result_set\u001b[38;5;241m.\u001b[39mseed, \n\u001b[1;32m     46\u001b[0m                 total_cost, mean_travel_time, network_vulnerability, is_connected))\n",
      "Cell \u001b[0;32mIn[67], line 33\u001b[0m, in \u001b[0;36mcalculate_network_vulnerability\u001b[0;34m(G, ref_travel_time, results)\u001b[0m\n\u001b[1;32m     30\u001b[0m G_copy \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     31\u001b[0m G_copy\u001b[38;5;241m.\u001b[39mremove_edge(\u001b[38;5;241m*\u001b[39me)\n\u001b[0;32m---> 33\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_pairs_shortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG_copy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m mean_time \u001b[38;5;241m=\u001b[39m calculate_mean_travel_time(distances)\n\u001b[1;32m     35\u001b[0m vuln \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(ref_travel_time \u001b[38;5;241m-\u001b[39m mean_time)\n",
      "File \u001b[0;32m~/CC/SEM2/Natural Computing/.venv/lib64/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:200\u001b[0m, in \u001b[0;36mall_pairs_shortest_path_length\u001b[0;34m(G, cutoff)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# TODO This can be trivially parallelized.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m G:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (n, \u001b[43mlength\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutoff\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 47:3\u001b[0m, in \u001b[0;36margmap_single_source_shortest_path_length_44\u001b[0;34m(G, source, cutoff, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "File \u001b[0;32m~/CC/SEM2/Natural Computing/.venv/lib64/python3.12/site-packages/networkx/utils/backends.py:967\u001b[0m, in \u001b[0;36m_dispatchable.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m backend \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetworkx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m backend is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# This is purely for aesthetics and to make it easier to search for this\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# variable since \"backend\" is used in many comments and log/error messages.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m~/CC/SEM2/Natural Computing/.venv/lib64/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:63\u001b[0m, in \u001b[0;36msingle_source_shortest_path_length\u001b[0;34m(G, source, cutoff)\u001b[0m\n\u001b[1;32m     61\u001b[0m     cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m nextlevel \u001b[38;5;241m=\u001b[39m [source]\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_single_shortest_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnextlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CC/SEM2/Natural Computing/.venv/lib64/python3.12/site-packages/networkx/algorithms/shortest_paths/unweighted.py:91\u001b[0m, in \u001b[0;36m_single_shortest_path_length\u001b[0;34m(adj, firstlevel, cutoff)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m thislevel:\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m adj[v]:\n\u001b[0;32m---> 91\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen:\n\u001b[1;32m     92\u001b[0m             seen\u001b[38;5;241m.\u001b[39madd(w)\n\u001b[1;32m     93\u001b[0m             nextlevel\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "proximities = range(1, 6) # Define the proximities we want to use: [1, 6), i.e., {1,2,3,4,5}\n",
    "proximities = [5]\n",
    "\n",
    "# Process experiments\n",
    "process_folder(\"../experiment_outputs_different_starts\", proximities)\n",
    "process_folder(\"../experiment_outputs_same_starts\", proximities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
