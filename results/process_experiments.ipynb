{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d72cc5-027d-433e-8db3-93266db564fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial import distance_matrix\n",
    "from tqdm.notebook import trange\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa2b3e1-8071-4f8a-9390-43d30f56bfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ResultSet:\n",
    "    \"\"\"\n",
    "    Helper class to keep all results from a single experiment together\n",
    "    \"\"\"\n",
    "    \n",
    "    all_trails: np.array\n",
    "    seed: np.array\n",
    "    nuclei: np.array\n",
    "    stations: np.array\n",
    "    map_with_stations: np.array\n",
    "    start_pos: np.array\n",
    "    all_points: np.array = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        points = self.nuclei.reshape(-1, 2)\n",
    "        points = points[~np.all(points == 0, axis=1)]  # Remove zero points\n",
    "        self.all_points = np.vstack([points, self.stations])\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Experiment with start pos {self.start_pos}, seed {self.seed}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "001822da-15f7-461e-8802-8c61506daa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nuclei_graph(results: ResultSet) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Creates a graph from all slime nuclei, where every node is connected to\n",
    "    its 10 closest neighbours\n",
    "    \"\"\"\n",
    "    \n",
    "    # 2. Build KDTree for fast neighbor search\n",
    "    tree = cKDTree(results.all_points)\n",
    "    \n",
    "    # 3. For each point, find its pm=10 nearest neighbors (excluding itself)\n",
    "    pm = 10\n",
    "    dists, idxs = tree.query(results.all_points, k=pm+1)  # +1 because first neighbor is itself\n",
    "    \n",
    "    # 4. Build the proximity graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # idxs: shape (N, pm+1), where idxs[i, 0] == i (self), idxs[i, 1:] are neighbors\n",
    "    src = np.repeat(np.arange(idxs.shape[0]), idxs.shape[1] - 1)\n",
    "    dst = idxs[:, 1:].reshape(-1) \n",
    "    edges = np.stack([src, dst], axis=1) # shape (N*(pm-1), 2)\n",
    "    \n",
    "    # Compute edge weights (Euclidean distances)\n",
    "    diffs = results.all_points[edges[:, 0]] - results.all_points[edges[:, 1]]\n",
    "    weights = np.linalg.norm(diffs, axis=1)\n",
    "    \n",
    "    # Add all edges at once to the graph\n",
    "    G.add_weighted_edges_from([(int(i), int(j), float(w)) for (i, j), w in zip(edges, weights)])\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f590b468-c6f2-4ca3-bb2f-19b42b88e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bresenham_line(x0, y0, x1, y1):\n",
    "    \"\"\"Yield integer coordinates on the line from (x0, y0) to (x1, y1) using Bresenham's algorithm.\"\"\"\n",
    "    x0, y0, x1, y1 = int(round(x0)), int(round(y0)), int(round(x1)), int(round(y1))\n",
    "    dx = abs(x1 - x0)\n",
    "    dy = abs(y1 - y0)\n",
    "    x, y = x0, y0\n",
    "    sx = 1 if x0 < x1 else -1\n",
    "    sy = 1 if y0 < y1 else -1\n",
    "    if dx > dy:\n",
    "        err = dx / 2.0\n",
    "        while x != x1:\n",
    "            yield x, y\n",
    "            err -= dy\n",
    "            if err < 0:\n",
    "                y += sy\n",
    "                err += dx\n",
    "            x += sx\n",
    "        yield x, y\n",
    "    else:\n",
    "        err = dy / 2.0\n",
    "        while y != y1:\n",
    "            yield x, y\n",
    "            err -= dx\n",
    "            if err < 0:\n",
    "                x += sx\n",
    "                err += dy\n",
    "            y += sy\n",
    "        yield x, y\n",
    "\n",
    "def prune_edges_by_map(G, result_set, max_water_crossings=2):\n",
    "    \"\"\"\n",
    "    Prunes illegal edges by checking the number of invalid pixels on a line \n",
    "    \"\"\"\n",
    "    pruned_graph = nx.Graph()\n",
    "    for i, j in G.edges():\n",
    "        x0, y0 = result_set.all_points[i]\n",
    "        x1, y1 = result_set.all_points[j]\n",
    "        # Sample the line between the two points\n",
    "        line_pixels = list(bresenham_line(x0, y0, x1, y1))\n",
    "        # Count how many pixels cross water (0)\n",
    "        water_crossings = sum(\n",
    "            result_set.map_with_stations[int(x), int(y)] == 0\n",
    "            for x, y in line_pixels\n",
    "            if 0 <= int(x) < result_set.map_with_stations.shape[0] and 0 <= int(y) < result_set.map_with_stations.shape[1]\n",
    "        )\n",
    "        if water_crossings <= max_water_crossings:\n",
    "            pruned_graph.add_edge(i, j, weight=G[i][j]['weight'])\n",
    "    return pruned_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa85a9b1-5096-4ae0-848a-8b517bdaa13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_refined_station_network(G, results, proximities):\n",
    "    \"\"\"\n",
    "    Build a refined network connecting each station to its p nearest station neighbors,\n",
    "    using only mesh edges from the original graph G.\n",
    "    \"\"\"\n",
    "    # Indices of station sources in all_points (they are last in the array)\n",
    "    station_indices = np.arange(results.all_points.shape[0] - len(results.stations), results.all_points.shape[0])\n",
    "\n",
    "    output = []\n",
    "    for p in proximities: output.append((p, nx.Graph(), set()))\n",
    "\n",
    "    for i in trange(len(station_indices)):\n",
    "        source = station_indices[i]\n",
    "        paths = []\n",
    "        for j in range(len(station_indices)):\n",
    "            if i == j: continue\n",
    "            try:\n",
    "                target = station_indices[j]\n",
    "                length, path = nx.single_source_dijkstra(G, source=source, target=target, weight='weight')\n",
    "                paths.append((length, path, target))\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "\n",
    "        paths = sorted(paths, key=lambda p: p[0])\n",
    "        \n",
    "        for p in range(len(proximities)):\n",
    "            p_graph = output[p][1]\n",
    "            for length, path, target in paths[:proximities[p]]:\n",
    "                if p_graph.has_edge(source, target):\n",
    "                    continue\n",
    "                p_graph.add_edge(source, target, weight=length)\n",
    "                output[p][2].update((min(path[k], path[k+1]), max(path[k], path[k+1])) for k in range(len(path)-1))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ec9761-c057-485f-a00c-5d5f59fc6b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_network_cost(G, path_edges):\n",
    "    \"\"\"\n",
    "    Calculates the cost of the total network\n",
    "    \"\"\"\n",
    "    total_cost = 0.0\n",
    "    for edge in path_edges:\n",
    "        if G.has_edge(edge[0], edge[1]):\n",
    "            total_cost += G[edge[0]][edge[1]]['weight']\n",
    "    return total_cost\n",
    "\n",
    "def calculate_mean_travel_time(G):\n",
    "    \"\"\"\n",
    "    Calculates the mean travel time on the network\n",
    "    \"\"\"\n",
    "    return G.size(weight='weight') / G.size()\n",
    "\n",
    "def calculate_network_vulnerability(G, ref_travel_time):\n",
    "    \"\"\"\n",
    "    Calculates the mean vulnerability on the network.\n",
    "    If the graph becomes disconnected after an edge is removed,\n",
    "    the vulnerability is then the weight of that edge.\n",
    "    \"\"\"\n",
    "    vulnerabilities = []\n",
    "    for e in G.edges():\n",
    "        # Create a copy of the graph to avoid modifying the original\n",
    "        G_copy = G.copy()\n",
    "        G_copy.remove_edge(*e)\n",
    "        mean_time = calculate_mean_travel_time(G_copy)\n",
    "        if nx.is_connected(G_copy):\n",
    "            vuln = np.abs(ref_travel_time - mean_time)\n",
    "        else:\n",
    "            vuln = G[e[0]][e[1]]['weight']\n",
    "        vulnerabilities.append(vuln)\n",
    "    return np.mean(vulnerabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08676f01-0ed4-4325-8cf3-4db77738c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(path: str) -> ResultSet:\n",
    "    \"\"\"\n",
    "    Process a single result file\n",
    "    \"\"\"\n",
    "    with np.load(path) as data:\n",
    "        return ResultSet(all_trails = data['all_trails'],\n",
    "                         seed = data['seed'],\n",
    "                         nuclei = data['nuclei'],\n",
    "                         stations = data['stations'],\n",
    "                         map_with_stations = data['map_with_stations'],\n",
    "                         start_pos = data['start_pos'])\n",
    "\n",
    "def process_folder(dir_path: str, proximities):\n",
    "    \"\"\"\n",
    "    Process a folder containing experiment result files.\n",
    "    \"\"\"\n",
    "    full_path = dir_path + \"/*.npz\"\n",
    "    files = glob(full_path)\n",
    "    \n",
    "    results = []\n",
    "    for i in range(len(files)):\n",
    "        path = files[i]\n",
    "        result_set = process_file(path)\n",
    "        full_graph = create_nuclei_graph(result_set)\n",
    "        pruned_graph = prune_edges_by_map(full_graph, result_set)\n",
    "        \n",
    "        for proximity, refined_graph, paths_set in build_refined_station_network(pruned_graph, result_set, proximities):\n",
    "            total_cost = calculate_network_cost(pruned_graph, paths_set)\n",
    "            mean_travel_time = calculate_mean_travel_time(refined_graph)\n",
    "            network_vulnerability = calculate_network_vulnerability(refined_graph, mean_travel_time)\n",
    "            is_connected = nx.is_connected(refined_graph)\n",
    "    \n",
    "            results.append((proximity, result_set.start_pos[0], result_set.start_pos[1], result_set.seed, \n",
    "                            total_cost, mean_travel_time, network_vulnerability, is_connected))\n",
    "    \n",
    "    df = pd.DataFrame(results, columns=[\"proximity\", \"start_pos_x\", \"start_pos_y\", \"seed\", \n",
    "                                        \"total_cost\", \"mean_travel_time\", \"vulnerability\", \"is_connected\"])\n",
    "    df_path = dir_path + f\"/results.csv\"\n",
    "    df.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448c0c8b-2825-4239-b80c-bf61959d7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "proximities = range(1, 6) # Define the proximities we want to use: [1, 6), i.e., {1,2,3,4,5}\n",
    "\n",
    "# Process experiments\n",
    "process_folder(\"../experiment_outputs_different_starts\", proximities)\n",
    "process_folder(\"../experiment_outputs_same_starts\", proximities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709049fc-6f0e-4816-b924-5cf6430194f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
